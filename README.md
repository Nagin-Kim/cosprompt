# Consprompt: Exploiting Contrastive Samples for Few-Shot Prompt Learning 
Prompt has become an effective linguistic tool for utilizing
pre-trained language models. However, in few-shot scenarios, subtle changes of prompt’s design always make the
result widely different, and the prompt learning methods
are also easy to overfit the limited samples. To alleviate
this, we explore utilizing suitable contrastive samples and
multi-degree contrastive learning methods to improve the robustness of prompt’s representation. Therefore, the proposed
Consprompt combined with prompt encoding network, contrastive sampling modules, and contrastive scoring modules,
is introduced to realize differential contrastive learning.


![image](https://github.com/Nagin-Kim/cosprompt/assets/24890015/a6e64667-882c-4446-9c27-83daffb4a532)


### our baseline use the code in :https://gitcode.com/princeton-nlp/LM-BFF
